{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800dcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#%%\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, StratifiedKFold, cross_validate, cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss, hinge_loss, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.plotting import table\n",
    "#%%\n",
    "data = pd.read_csv('Machine learning.csv')\n",
    "data.head()\n",
    "#%% md\n",
    "# DATA PROCESSING\n",
    "#%%\n",
    "data.info()\n",
    "#%%\n",
    "data.describe()\n",
    "#%% md\n",
    "# Scaling and Encoding\n",
    "#%%\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "norm = MinMaxScaler()\n",
    "encode = LabelEncoder()\n",
    "#%%\n",
    "data['Location'] = encode.fit_transform(data['Location'])\n",
    "data.head()\n",
    "#%%\n",
    "Data_x = data.iloc[:,:-1]\n",
    "Data_x\n",
    "col = list(Data_x.keys())\n",
    "Data_tf = pd.DataFrame(data=norm.fit_transform(Data_x), columns=col)\n",
    "Data_tf['Bioturbation Index'] = data.iloc[:,-1]\n",
    "Data_tf.head()\n",
    "#%% md\n",
    "# Feature selection using SelectKBest\n",
    "#%%\n",
    "fe_selection = SelectKBest(score_func=f_classif, k=8).fit_transform(Data_tf.iloc[:,:-1],Data_tf.iloc[:,-1])\n",
    "fe_selection.shape\n",
    "feat_select = pd.DataFrame(fe_selection)\n",
    "feat_select.head(5)\n",
    "#%%\n",
    "feat_select = SelectKBest(score_func=f_classif, k=5).fit(data.iloc[:,:-1],data.iloc[:,-1])\n",
    "param = pd.DataFrame()\n",
    "param['features'] = data.iloc[:,:-1].columns\n",
    "param['f_score'] = feat_select.scores_\n",
    "param['P_values'] = feat_select.pvalues_\n",
    "param['Features_bool'] = feat_select.get_support()\n",
    "param= param.sort_values(by='f_score', ascending=False)\n",
    "param = param.round(5)\n",
    "param\n",
    "#%%\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.bar(param['features'], param['P_values'])\n",
    "plt.ylabel('P-Values')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Features P-values')\n",
    "plt.savefig('P-Values')\n",
    "#%%\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(param['features'],1 - param['P_values'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('P-Values')\n",
    "plt.title('Features {1-} P-values')\n",
    "plt.savefig('1-(P-Values)')\n",
    "#%%\n",
    "New_data = Data_tf.drop(['Sample Length','Particle Volume','Dry Weight','Sample Volume','Pore Volume','Bioturbation Index'], axis=1)\n",
    "New_data['Bioturbation Index'] = Data_tf.iloc[:,-1]\n",
    "New_data.head()\n",
    "#%%\n",
    "corr = New_data.corr()\n",
    "plt.figure(figsize= (11,8))\n",
    "sns.heatmap(corr, annot=True, cbar=True)\n",
    "#%%\n",
    "#sns.pairplot(New_data,hue='Bioturbation Index', palette= ['red', 'green','blue','violet','purple'])\n",
    "#%% md\n",
    "# Data splitting, Cross_validation and Retraining\n",
    "#%%\n",
    "X = New_data.iloc[:,:-1]\n",
    "y = New_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)\n",
    "print('X_train shape = ', X_train.shape )\n",
    "print('X_test shape = ', X_test.shape )\n",
    "print('y_train shape = ', y_train.shape )\n",
    "print('y_test shape = ', y_test.shape )\n",
    "#%%\n",
    "Cl_svc = SVC()\n",
    "Cl_lda = LinearDiscriminantAnalysis()\n",
    "models = [ Cl_svc, Cl_lda]\n",
    "#%%\n",
    "splits = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "SVCcv_scr = cross_validate(Cl_svc, X_train, y_train, cv=splits, return_estimator=True, return_train_score=True)\n",
    "\n",
    "ldacv_scr = cross_validate(Cl_lda, X_train, y_train, cv=splits, return_estimator=True, return_train_score=True)\n",
    "#%%\n",
    "scores = pd.DataFrame({'SVC': (1-SVCcv_scr['train_score']),\n",
    "                       'LDA': (1-ldacv_scr['train_score'])})\n",
    "scores\n",
    "#%%\n",
    "print('SVC: ',SVCcv_scr['train_score'].mean())\n",
    "print('LDA: ',ldacv_scr['train_score'].mean())\n",
    "#%%\n",
    "k_neighbors =  range(3,11,2)\n",
    "for k in k_neighbors:\n",
    "    Cl_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knncv_scr = cross_validate(Cl_knn, X_train, y_train, cv=splits, return_estimator=True, return_train_score=True)\n",
    "    knnscore = pd.DataFrame({k: knncv_scr['train_score']})   \n",
    "    print(knnscore)\n",
    "#%% md\n",
    "\n",
    "#%%\n",
    "CRS_pred = SVCcv_scr['estimator'][0].predict(X_train)\n",
    "CRS_report = classification_report(y_train,CRS_pred, target_names=[\"Class 0\",\"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"])\n",
    "print(CRS_report)\n",
    "#%%\n",
    "CRS_pred = SVCcv_scr['estimator'][0].predict(X_train)\n",
    "CRS_report = confusion_matrix(y_train,CRS_pred)\n",
    "print(CRS_report)\n",
    "#%%\n",
    "CRK_pred = knncv_scr['estimator'][0].predict(X_train)\n",
    "CRK_report = confusion_matrix(y_train,CRK_pred)\n",
    "print(CRK_report)\n",
    "#%%\n",
    "CRL_pred = ldacv_scr['estimator'][0].predict(X_train)\n",
    "CRL_report = confusion_matrix(y_train,CRL_pred)\n",
    "print(CRL_report)\n",
    "#%% md\n",
    "# Optimization with Gridsearchcv\n",
    "#%%\n",
    "gdModel = KNeighborsClassifier()\n",
    "params = [{ 'n_neighbors':[3,5,7,9],\n",
    "            'weights' : ['uniform', 'distance'],\n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "             'leaf_size' : [5,10,15,10]\n",
    "          }]\n",
    "Gdkmodel = GridSearchCV(estimator=gdModel, param_grid=params, scoring='accuracy', return_train_score=True, cv=splits)\n",
    "Gdkmodel.fit(X_train, y_train)\n",
    "print(Gdkmodel.best_params_)\n",
    "print(Gdkmodel.best_score_)\n",
    "#%%\n",
    "gdsModel = SVC()\n",
    "params = [{'C': [0.1, 1, 10, 100, 1000],\n",
    "           'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "           'kernel': ['rbf', 'linear']\n",
    "          }]\n",
    "Gdsmodel = GridSearchCV(estimator=gdsModel, param_grid=params, scoring='accuracy', return_train_score=True, cv=splits)\n",
    "Gdsmodel.fit(X_train, y_train)\n",
    "print(Gdsmodel.best_params_)\n",
    "print(Gdsmodel.best_score_)\n",
    "#%%\n",
    "gdlModel =  LinearDiscriminantAnalysis()\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'eigen','lsqr']\n",
    "grid['shrinkage'] = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,]\n",
    "Gdlmodel = GridSearchCV(gdlModel, param_grid = grid, scoring='accuracy', return_train_score=True, cv=splits)\n",
    "Gdlmodel.fit(X_train, y_train)\n",
    "print('Best Prams:', Gdlmodel.best_params_)\n",
    "print('Best Score:', Gdlmodel.best_score_)\n",
    "\n",
    "#%%\n",
    "from sklearn.metrics import accuracy_score\n",
    "#%%\n",
    "for k in range(3,11,2):#'algorithm': 'auto', 'leaf_size': 5, 'n_neighbors': 3, 'weights': 'uniform'\n",
    "    cl_knn1 = KNeighborsClassifier(n_neighbors=k,algorithm='auto',leaf_size=5, weights='uniform')\n",
    "    cl_knn1.fit(X_train,y_train)\n",
    "    knn_pred = cl_knn1.predict(X_train)\n",
    "    knn_prob = cl_knn1.predict_proba(X_test)\n",
    "    print(cl_knn1.score(X_train, y_train))\n",
    "#%%\n",
    "C= [1,10,100,1000]\n",
    "for c in C:\n",
    "    cl_svm = SVC(C=c, gamma=0.01,kernel='rbf')\n",
    "    cl_svm.fit(X_train,y_train)\n",
    "    svm_pred = cl_svm.predict(X_train)\n",
    "    print(cl_svm.score(X_train, y_train))\n",
    "#%% md\n",
    "# TRAINING AND TESTING OF BEST HYPERPARAMETERS\n",
    "#%%\n",
    "#Best Prams: {'shrinkage': 0.9, 'solver': 'eigen'}\n",
    "cl_lda = LinearDiscriminantAnalysis(shrinkage=0.9, solver='eigen')\n",
    "cl_lda.fit(X_train,y_train)\n",
    "lda_pred = cl_lda.predict(X_train)\n",
    "lda_prob = cl_lda.predict_proba(X_test)\n",
    "print(cl_lda.score(X_train, y_train))\n",
    "Ldatest_prediction = cl_lda.predict(X_test)\n",
    "#%%\n",
    "svm_train = SVC(C=100, kernel='rbf', gamma=1)\n",
    "svm_train.fit(X_train,y_train)\n",
    "print(svm_train.score(X_train,y_train))\n",
    "Svmtest_prediction = svm_train.predict(X_test)\n",
    "#%%\n",
    "knn_train = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_train.fit(X_train, y_train)\n",
    "print(knn_train.score(X_train, y_train))\n",
    "Knntest_prediction = knn_train.predict(X_test)\n",
    "#%%\n",
    "y_test = list(y_test)\n",
    "outcomes = pd.DataFrame(data=y_test, columns=['Actual value'])\n",
    "outcomes['KNN_PRED'] = Knntest_prediction\n",
    "outcomes['LDA_PRED'] = Ldatest_prediction\n",
    "outcomes['SVM_PRED'] = Svmtest_prediction\n",
    "outcomes\n",
    "#%% md\n",
    "\n",
    "#%%\n",
    "# TESTING OF DATASETS\n",
    "print('KNN Accuracy: ', accuracy_score(y_test, Knntest_prediction))\n",
    "print('SVM Accuracy: ', accuracy_score(y_test, Svmtest_prediction))\n",
    "print('LDA Accuracy: ', accuracy_score(y_test, Ldatest_prediction))\n",
    "#%% md\n",
    "\n",
    "#%% md\n",
    "\n",
    "#%% md\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
